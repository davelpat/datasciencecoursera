---
title: "Financial and Health Impacts of U.S. Storms From 1996 Through 2011"
author: "Dave Patterson"
date: "September 13, 2015"
output: 
  html_document: 
    keep_md: yes
---

## Synopsis
The purpose of this report is to explore the NOAA Storm Database and analyze the types of 
storm events to understand  
1. which are most harmful with respect to population health and  
2. which have the greatest economic consequences?  
This analysis should help to prioritize resources to prepare for severe weather events.

## Data Processing

The following code blocks loads the required packages, downloads a copy of the 
U.S. National Oceanic and Atmospheric Administration's (NOAA) storm database from the 
course repository for all the storms in the U.S. from 1950 through 2011.

```{r load libs}
packages <- c("data.table", "dplyr", "lubridate", "stringr", "ggplot2")
sapply(packages, require, character.only = TRUE, quietly = TRUE)
```

```{r get files}
original_data  <- "http://www.ncdc.noaa.gov/stormevents/details.jsp"
storm_data_url <- "http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
storm_data_doc <- "http://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf"
storm_data_faq <- "http://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2FNCDC%20Storm%20Events-FAQ%20Page.pdf"
storm_data_bz2 <- "StormData.csv.bz2"
storm_data_events_file <- "StormDataEventTable.csv"

# if the data file is not already present, get the source data file
if(!(file.exists(storm_data_bz2))) {download.file(storm_data_url, destfile = storm_data_bz2)}
```

Next, we read in the data and prepare it for analysis. Given the large volume of data 
(over 900,000 storm events), we only read in the data needed to answer the two questions 
of interest. This will eliminate two thirds of the data fields and simplify the processing, 
as well as speed up the processing of the data In the list below, "NULL" indicates 
that data field is ignored in this analysis.

```{r select variables}
# grab the headers
storm_data_headers <- names(read.csv(storm_data_bz2, header = T, nrow = 1))
# create a vector to ignore most of the variables when we read them in since we're not
# interested in most of them -- only in data the can affect the answers
# i.e. storm data that impacts health or property
header_char_classes <- rep("NULL", 37)
# set the variables we are interested in to type char so they read in quickly
header_char_classes[c(2,8,23:28,36:37)] <- "character"
# verify the mapping
cbind(storm_data_headers, header_char_classes)
```

Prior to 1996, there was no standard classification of storm types. Effective beginnning in 1996, 
storm events were grouped into 48 standard event types. Prior to that, the storm data was 
both sparse and inconsistent. In addition, due to inflation, the value of money prior to 1996
in comparison to today was significantly great enough to potentially skew the data. 
For these reasons, we will only work with the last 15 years of the dataset. 
This still leaves about two thirds of the storm events in the dataset.

```{r read data, cache=TRUE}
# read in only the variables we're interested in and only the data after the new stardard has gone into effect
# Ignoring the early data removes the most noise and about a third of the data 
storm_data <- tbl_df(read.csv(storm_data_bz2, 
                              stringsAsFactors=FALSE, 
                              colClasses = header_char_classes))  %>% 
              mutate(BGN_DATE =  mdy_hms(BGN_DATE)) %>% 
              filter(BGN_DATE >= "1996-01-01")
```

This still leaves us with nearly two thirds of a million storm events, many of which 
have no impact on the questions we are looking to answer. The following code block 
corrects the data types and filters out storm events that were reported to have 
no financial or health impact. This eliminates more than two thirds of the storm events 
in the 15 year period, but still leaves a bit over 200,000 storm events, 
all of which have a bearing on our two questions.

```{r filter data, cache=TRUE}
# coerce the numeric data to be the correct type
storm_data <- storm_data %>% 
              mutate(FATALITIES = as.integer(FATALITIES),
                     INJURIES = as.integer(INJURIES),
                     PROPDMG = as.numeric(PROPDMG),
                     CROPDMG = as.numeric(CROPDMG),
                     REFNUM = as.integer(REFNUM))
# finally keep only the storm data that can affect the questions; this removes
# about two thirds of the remaining data, none of which helps answer the questions
# since we're looking at totals, not averages
storm_data <- storm_data %>% 
              filter(FATALITIES > 0 | INJURIES > 0 | PROPDMG > 0 | CROPDMG > 0)
```

In a first look at the storm data, we can see the storm event types do not always align 
with the standard event names.

```{r event names}
# read in the standard event types used starting 1996
# extracted from storm_data_doc file (Table 1. Storm Data Event Table)
standard_events <- read.csv(storm_data_events_file, comment.char = "#", stringsAsFactors = FALSE)

# and from our storm data
storm_data_events <- unique(storm_data$EVTYPE)
```

The storm data contains **`r length(storm_data_events)`** unique storm event types in contrast 
to the `r length(standard_events$Event.Name)` standard event types. It would greatly simplfy the
analysis if the `r length(storm_data_events)` unique storm event types could be grouped into the
`r length(standard_events$Event.Name)` standard event types. Since we're dealing with 
`r length(storm_data$EVTYPE)` storm events, it is obvious that we'll need some tools to help with 
the analysis. These functions were useful in exploring the storm data.

```{r useful functions}
# define a function to aid in generating regexps to group events into std types
get_event <- function(src, pattern) {
               unique(grep(pattern, 
                           src, 
                           ignore.case = TRUE, 
                           value = TRUE))}
# and an example call
# get_event(events, "^\\s*(tstm|thunder)")

# define a function to get the remarks for a specific storm reference
get_remarks_for <- function(ref) {
  storm_data[(storm_data$REFNUM == ref),"REMARKS"]
}
```

```{r clean events}
# look for outliers that may distort the results; correct or exclude
```

```{r health impact}
```

```{r financial impact}
```

